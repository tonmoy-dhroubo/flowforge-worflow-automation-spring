This document contains the source code for the project "trigger".
Only files with the following extensions are included: .html, .css, .scss, .less, .json, .yml, .yaml, .java, .properties, .xml, .sql, .md, .py, .sh

The folder structure is as follows:

trigger
├── .mvn
│   └── wrapper
│       └── maven-wrapper.properties
├── pom.xml
└── src
    └── main
        ├── java
        │   └── com
        │       └── flowforge
        │           └── trigger
        │               ├── config
        │               │   ├── KafkaProducerConfig.java
        │               │   ├── SchedulerConfig.java
        │               │   └── TriggerPluginRegistry.java
        │               ├── controller
        │               │   ├── ManualTriggerController.java
        │               │   ├── TriggerPluginController.java
        │               │   └── WebhookController.java
        │               ├── dto
        │               │   ├── ScheduleTrigger.java
        │               │   ├── TriggerEvent.java
        │               │   ├── WebhookRequest.java
        │               │   └── WebhookResponse.java
        │               ├── exception
        │               │   └── GlobalExceptionHandler.java
        │               ├── kafka
        │               │   └── producer
        │               │       └── TriggerEventProducer.java
        │               ├── plugin
        │               │   ├── BaseTriggerPlugin.java
        │               │   ├── impl
        │               │   │   ├── EmailTriggerPlugin.java
        │               │   │   ├── ScheduleTriggerPlugin.java
        │               │   │   └── WebhookTriggerPlugin.java
        │               │   ├── TriggerPlugin.java
        │               │   └── TriggerPluginManager.java
        │               ├── service
        │               │   ├── SchedulerService.java
        │               │   └── TriggerService.java
        │               └── TriggerApplication.java
        └── resources
            └── application.yml


----------------------------------------

// FILE: .mvn\wrapper\maven-wrapper.properties
========================================
wrapperVersion=3.3.4
distributionType=only-script
distributionUrl=https://repo.maven.apache.org/maven2/org/apache/maven/apache-maven/3.9.11/apache-maven-3.9.11-bin.zip


// FILE: pom.xml
========================================
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<parent>
		<groupId>com.flowforge</groupId>
		<artifactId>flowforge-parent</artifactId>
		<version>0.0.1-SNAPSHOT</version>
		<relativePath>../pom.xml</relativePath> <!-- Points to the root pom -->
	</parent>
    <artifactId>trigger</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>trigger</name>
	<description>Workflow Automation</description>
	<url/>
	<licenses>
		<license/>
	</licenses>
	<developers>
		<developer/>
	</developers>
	<scm>
		<connection/>
		<developerConnection/>
		<tag/>
		<url/>
	</scm>
	<properties>
		<java.version>25</java.version>
	</properties>
	<dependencies>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.kafka</groupId>
			<artifactId>spring-kafka</artifactId>
		</dependency>

		<dependency>
			<groupId>org.projectlombok</groupId>
			<artifactId>lombok</artifactId>
			<optional>true</optional>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.springframework.kafka</groupId>
			<artifactId>spring-kafka-test</artifactId>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<annotationProcessorPaths>
						<path>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
						</path>
					</annotationProcessorPaths>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
				<configuration>
					<excludes>
						<exclude>
							<groupId>org.projectlombok</groupId>
							<artifactId>lombok</artifactId>
						</exclude>
					</excludes>
				</configuration>
			</plugin>
		</plugins>
	</build>

</project>


// FILE: src\main\java\com\flowforge\trigger\config\KafkaProducerConfig.java
========================================
package com.flowforge.trigger.config;

import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;
import org.springframework.kafka.support.serializer.JsonSerializer;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaProducerConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        configProps.put(JsonSerializer.ADD_TYPE_INFO_HEADERS, false);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}

// FILE: src\main\java\com\flowforge\trigger\config\SchedulerConfig.java
========================================
package com.flowforge.trigger.config;

import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.scheduling.TaskScheduler;
import org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler;

@Configuration
public class SchedulerConfig {
    
    @Bean
    public TaskScheduler taskScheduler() {
        ThreadPoolTaskScheduler scheduler = new ThreadPoolTaskScheduler();
        scheduler.setPoolSize(10);
        scheduler.setThreadNamePrefix("trigger-scheduler-");
        scheduler.setWaitForTasksToCompleteOnShutdown(true);
        scheduler.setAwaitTerminationSeconds(60);
        scheduler.initialize();
        return scheduler;
    }
}

// FILE: src\main\java\com\flowforge\trigger\config\TriggerPluginRegistry.java
========================================
package com.flowforge.trigger.config;

import com.flowforge.trigger.plugin.TriggerPlugin;
import com.flowforge.trigger.plugin.TriggerPluginManager;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.event.ContextRefreshedEvent;
import org.springframework.context.event.EventListener;

import java.util.List;

/**
 * Automatically registers all Spring-managed TriggerPlugin beans
 * with the TriggerPluginManager on application startup.
 */
@Configuration
@RequiredArgsConstructor
@Slf4j
public class TriggerPluginRegistry {
    
    private final TriggerPluginManager pluginManager;
    private final List<TriggerPlugin> triggerPlugins;
    
    @EventListener(ContextRefreshedEvent.class)
    public void registerPlugins() {
        log.info("Registering {} built-in trigger plugins...", triggerPlugins.size());
        
        for (TriggerPlugin plugin : triggerPlugins) {
            pluginManager.registerPlugin(plugin);
        }
        
        log.info("Built-in trigger plugins registered successfully");
    }
}

// FILE: src\main\java\com\flowforge\trigger\controller\ManualTriggerController.java
========================================
package com.flowforge.trigger.controller;

import com.flowforge.trigger.dto.WebhookResponse;
import com.flowforge.trigger.service.SchedulerService;
import com.flowforge.trigger.service.TriggerService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

import java.util.Map;

@RestController
@RequestMapping("/api/v1/triggers")
@RequiredArgsConstructor
@Slf4j
public class ManualTriggerController {

    private final TriggerService triggerService;
    private final SchedulerService schedulerService;

    /**
     * Manually trigger a workflow
     */
    @PostMapping("/manual/{workflowId}")
    public ResponseEntity<WebhookResponse> triggerWorkflowManually(
            @PathVariable String workflowId,
            @RequestBody(required = false) Map<String, Object> payload) {
        
        log.info("Manual trigger requested for workflow: {}", workflowId);
        
        String eventId = triggerService.createManualTrigger(workflowId, payload);
        
        WebhookResponse response = WebhookResponse.builder()
                .eventId(eventId)
                .status("accepted")
                .message("Manual trigger accepted for workflow: " + workflowId)
                .build();
        
        return ResponseEntity.ok(response);
    }

    /**
     * Manually trigger a schedule
     */
    @PostMapping("/schedule/{scheduleName}")
    public ResponseEntity<WebhookResponse> triggerScheduleManually(
            @PathVariable String scheduleName,
            @RequestBody(required = false) Map<String, Object> config) {
        
        log.info("Manual schedule trigger requested: {}", scheduleName);
        
        String eventId = schedulerService.triggerCustomSchedule(scheduleName, config);
        
        WebhookResponse response = WebhookResponse.builder()
                .eventId(eventId)
                .status("accepted")
                .message("Schedule trigger accepted: " + scheduleName)
                .build();
        
        return ResponseEntity.ok(response);
    }
}

// FILE: src\main\java\com\flowforge\trigger\controller\TriggerPluginController.java
========================================
package com.flowforge.trigger.controller;

import com.flowforge.trigger.plugin.TriggerPlugin;
import com.flowforge.trigger.plugin.TriggerPluginManager;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

import java.util.HashMap;
import java.util.Map;
import java.util.stream.Collectors;

/**
 * REST API for managing trigger plugins
 */
@RestController
@RequestMapping("/api/v1/plugins")
@RequiredArgsConstructor
@Slf4j
public class TriggerPluginController {
    
    private final TriggerPluginManager pluginManager;
    
    /**
     * List all available trigger plugins
     */
    @GetMapping
    public ResponseEntity<Map<String, Object>> listPlugins() {
        Map<String, TriggerPlugin> plugins = pluginManager.getAllPlugins();
        
        Map<String, Object> response = new HashMap<>();
        response.put("count", plugins.size());
        response.put("plugins", plugins.values().stream()
            .map(plugin -> Map.of(
                "type", plugin.getType(),
                "name", plugin.getName(),
                "description", plugin.getDescription(),
                "healthy", plugin.isHealthy(),
                "configSchema", plugin.getConfigSchema()
            ))
            .collect(Collectors.toList()));
        
        return ResponseEntity.ok(response);
    }
    
    /**
     * Get details of a specific plugin
     */
    @GetMapping("/{type}")
    public ResponseEntity<Map<String, Object>> getPlugin(@PathVariable String type) {
        return pluginManager.getPlugin(type)
            .map(plugin -> {
                Map<String, Object> response = new HashMap<>();
                response.put("type", plugin.getType());
                response.put("name", plugin.getName());
                response.put("description", plugin.getDescription());
                response.put("configSchema", plugin.getConfigSchema());
                response.put("status", plugin.getStatus());
                response.put("healthy", plugin.isHealthy());
                return ResponseEntity.ok(response);
            })
            .orElse(ResponseEntity.notFound().build());
    }
    
    /**
     * Get plugin status
     */
    @GetMapping("/{type}/status")
    public ResponseEntity<Map<String, Object>> getPluginStatus(@PathVariable String type) {
        return pluginManager.getPlugin(type)
            .map(plugin -> ResponseEntity.ok(plugin.getStatus()))
            .orElse(ResponseEntity.notFound().build());
    }
    
    /**
     * Get all plugins status
     */
    @GetMapping("/status")
    public ResponseEntity<Map<String, Object>> getAllPluginsStatus() {
        return ResponseEntity.ok(pluginManager.getPluginsStatus());
    }
    
    /**
     * Reload all plugins (hot-reload)
     */
    @PostMapping("/reload")
    public ResponseEntity<Map<String, Object>> reloadAllPlugins() {
        log.info("Reloading all trigger plugins...");
        
        try {
            pluginManager.reloadAllPlugins();
            
            Map<String, Object> response = new HashMap<>();
            response.put("status", "success");
            response.put("message", "All plugins reloaded successfully");
            response.put("pluginCount", pluginManager.getAllPlugins().size());
            
            return ResponseEntity.ok(response);
        } catch (Exception e) {
            log.error("Error reloading plugins", e);
            
            Map<String, Object> response = new HashMap<>();
            response.put("status", "error");
            response.put("message", "Failed to reload plugins: " + e.getMessage());
            
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).body(response);
        }
    }
    
    /**
     * Reload a specific plugin
     */
    @PostMapping("/{type}/reload")
    public ResponseEntity<Map<String, Object>> reloadPlugin(@PathVariable String type) {
        log.info("Reloading trigger plugin: {}", type);
        
        try {
            pluginManager.reloadPlugin(type);
            
            Map<String, Object> response = new HashMap<>();
            response.put("status", "success");
            response.put("message", "Plugin reloaded successfully");
            response.put("type", type);
            
            return ResponseEntity.ok(response);
        } catch (Exception e) {
            log.error("Error reloading plugin: {}", type, e);
            
            Map<String, Object> response = new HashMap<>();
            response.put("status", "error");
            response.put("message", "Failed to reload plugin: " + e.getMessage());
            
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).body(response);
        }
    }
    
    /**
     * Start a trigger for a workflow
     */
    @PostMapping("/{type}/start")
    public ResponseEntity<Map<String, Object>> startTrigger(
            @PathVariable String type,
            @RequestParam String workflowId,
            @RequestBody Map<String, Object> config) {
        
        log.info("Starting trigger {} for workflow: {}", type, workflowId);
        
        try {
            pluginManager.startTrigger(type, workflowId, config);
            
            Map<String, Object> response = new HashMap<>();
            response.put("status", "success");
            response.put("message", "Trigger started successfully");
            response.put("type", type);
            response.put("workflowId", workflowId);
            
            return ResponseEntity.ok(response);
        } catch (Exception e) {
            log.error("Error starting trigger", e);
            
            Map<String, Object> response = new HashMap<>();
            response.put("status", "error");
            response.put("message", e.getMessage());
            
            return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(response);
        }
    }
    
    /**
     * Stop a trigger for a workflow
     */
    @PostMapping("/{type}/stop")
    public ResponseEntity<Map<String, Object>> stopTrigger(
            @PathVariable String type,
            @RequestParam String workflowId) {
        
        log.info("Stopping trigger {} for workflow: {}", type, workflowId);
        
        try {
            pluginManager.stopTrigger(type, workflowId);
            
            Map<String, Object> response = new HashMap<>();
            response.put("status", "success");
            response.put("message", "Trigger stopped successfully");
            response.put("type", type);
            response.put("workflowId", workflowId);
            
            return ResponseEntity.ok(response);
        } catch (Exception e) {
            log.error("Error stopping trigger", e);
            
            Map<String, Object> response = new HashMap<>();
            response.put("status", "error");
            response.put("message", e.getMessage());
            
            return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(response);
        }
    }
    
    /**
     * Validate trigger configuration
     */
    @PostMapping("/{type}/validate")
    public ResponseEntity<Map<String, Object>> validateConfig(
            @PathVariable String type,
            @RequestBody Map<String, Object> config) {
        
        return pluginManager.getPlugin(type)
            .map(plugin -> {
                boolean valid = plugin.validateConfig(config);
                
                Map<String, Object> response = new HashMap<>();
                response.put("valid", valid);
                response.put("type", type);
                
                if (!valid) {
                    response.put("message", "Invalid configuration");
                }
                
                return ResponseEntity.ok(response);
            })
            .orElse(ResponseEntity.notFound().build());
    }
}

// FILE: src\main\java\com\flowforge\trigger\controller\WebhookController.java
========================================
package com.flowforge.trigger.controller;

import com.flowforge.trigger.dto.TriggerEvent;
import com.flowforge.trigger.dto.WebhookRequest;
import com.flowforge.trigger.dto.WebhookResponse;
import com.flowforge.trigger.service.TriggerService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

import jakarta.servlet.http.HttpServletRequest;
import java.time.Instant;
import java.util.HashMap;
import java.util.Map;
import java.util.UUID;

@RestController
@RequestMapping("/api/v1/webhooks")
@RequiredArgsConstructor
@Slf4j
public class WebhookController {

    private final TriggerService triggerService;

    /**
     * Generic webhook endpoint that accepts any event
     */
    @PostMapping("/{workflowId}")
    public ResponseEntity<WebhookResponse> handleWebhook(
            @PathVariable String workflowId,
            @RequestBody(required = false) Map<String, Object> payload,
            HttpServletRequest request) {
        
        log.info("Received webhook for workflow: {}", workflowId);

        // Extract headers
        Map<String, String> headers = new HashMap<>();
        request.getHeaderNames().asIterator()
            .forEachRemaining(name -> headers.put(name, request.getHeader(name)));

        // Create trigger event
        String eventId = UUID.randomUUID().toString();
        TriggerEvent event = TriggerEvent.builder()
                .eventId(eventId)
                .triggerType("webhook")
                .payload(payload != null ? payload : new HashMap<>())
                .metadata(Map.of(
                    "workflowId", workflowId,
                    "method", request.getMethod(),
                    "remoteAddr", request.getRemoteAddr(),
                    "contentType", request.getContentType() != null ? request.getContentType() : "unknown"
                ))
                .timestamp(Instant.now())
                .build();

        // Send to Kafka
        triggerService.processTrigger(event);

        WebhookResponse response = WebhookResponse.builder()
                .eventId(eventId)
                .status("accepted")
                .message("Webhook received and queued for processing")
                .build();

        return ResponseEntity.status(HttpStatus.ACCEPTED).body(response);
    }

    /**
     * Named event webhook endpoint
     */
    @PostMapping("/events/{eventName}")
    public ResponseEntity<WebhookResponse> handleNamedEvent(
            @PathVariable String eventName,
            @RequestBody WebhookRequest webhookRequest) {
        
        log.info("Received named event: {}", eventName);

        String eventId = UUID.randomUUID().toString();
        TriggerEvent event = TriggerEvent.builder()
                .eventId(eventId)
                .triggerType("webhook." + eventName)
                .payload(webhookRequest.getData() != null ? webhookRequest.getData() : new HashMap<>())
                .metadata(Map.of(
                    "eventName", eventName,
                    "requestEvent", webhookRequest.getEvent() != null ? webhookRequest.getEvent() : "unknown"
                ))
                .timestamp(Instant.now())
                .build();

        triggerService.processTrigger(event);

        WebhookResponse response = WebhookResponse.builder()
                .eventId(eventId)
                .status("accepted")
                .message("Event received and queued for processing")
                .build();

        return ResponseEntity.status(HttpStatus.ACCEPTED).body(response);
    }

    /**
     * Health check endpoint
     */
    @GetMapping("/health")
    public ResponseEntity<Map<String, String>> healthCheck() {
        return ResponseEntity.ok(Map.of(
            "status", "UP",
            "service", "trigger-service",
            "timestamp", Instant.now().toString()
        ));
    }

    /**
     * Test webhook endpoint (for testing purposes)
     */
    @PostMapping("/test")
    public ResponseEntity<WebhookResponse> testWebhook(@RequestBody Map<String, Object> payload) {
        log.info("Received test webhook");

        String eventId = UUID.randomUUID().toString();
        TriggerEvent event = TriggerEvent.builder()
                .eventId(eventId)
                .triggerType("webhook.test")
                .payload(payload)
                .metadata(Map.of("test", "true"))
                .timestamp(Instant.now())
                .build();

        triggerService.processTrigger(event);

        WebhookResponse response = WebhookResponse.builder()
                .eventId(eventId)
                .status("accepted")
                .message("Test webhook processed successfully")
                .build();

        return ResponseEntity.ok(response);
    }
}

// FILE: src\main\java\com\flowforge\trigger\dto\ScheduleTrigger.java
========================================
package com.flowforge.trigger.dto;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.Map;

@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class ScheduleTrigger {
    private String triggerId;
    private String cronExpression;
    private Map<String, Object> config;
    private boolean enabled;
}

// FILE: src\main\java\com\flowforge\trigger\dto\TriggerEvent.java
========================================
package com.flowforge.trigger.dto;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.time.Instant;
import java.util.Map;
import java.util.UUID;

@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class TriggerEvent {
    private String eventId;
    private String triggerType;  // webhook, schedule, manual, etc.
    private Map<String, Object> payload;
    private Map<String, String> metadata;
    private Instant timestamp;
    
    @Builder.Default
    private Instant createdAt = Instant.now();
}

// FILE: src\main\java\com\flowforge\trigger\dto\WebhookRequest.java
========================================
package com.flowforge.trigger.dto;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.Map;

@Data
@NoArgsConstructor
@AllArgsConstructor
public class WebhookRequest {
    private String event;
    private Map<String, Object> data;
}

// FILE: src\main\java\com\flowforge\trigger\dto\WebhookResponse.java
========================================
package com.flowforge.trigger.dto;

import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class WebhookResponse {
    private String eventId;
    private String status;
    private String message;
}

// FILE: src\main\java\com\flowforge\trigger\exception\GlobalExceptionHandler.java
========================================
package com.flowforge.trigger.exception;

import lombok.extern.slf4j.Slf4j;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.context.request.WebRequest;

import java.time.LocalDateTime;
import java.util.LinkedHashMap;
import java.util.Map;

@ControllerAdvice
@Slf4j
public class GlobalExceptionHandler {

    @ExceptionHandler(Exception.class)
    public ResponseEntity<Object> handleGlobalException(Exception ex, WebRequest request) {
        log.error("Unexpected error occurred", ex);
        
        Map<String, Object> body = new LinkedHashMap<>();
        body.put("timestamp", LocalDateTime.now());
        body.put("status", HttpStatus.INTERNAL_SERVER_ERROR.value());
        body.put("error", "Internal Server Error");
        body.put("message", ex.getMessage());
        body.put("path", request.getDescription(false).replace("uri=", ""));

        return new ResponseEntity<>(body, HttpStatus.INTERNAL_SERVER_ERROR);
    }

    @ExceptionHandler(IllegalArgumentException.class)
    public ResponseEntity<Object> handleIllegalArgumentException(IllegalArgumentException ex, WebRequest request) {
        log.error("Illegal argument error", ex);
        
        Map<String, Object> body = new LinkedHashMap<>();
        body.put("timestamp", LocalDateTime.now());
        body.put("status", HttpStatus.BAD_REQUEST.value());
        body.put("error", "Bad Request");
        body.put("message", ex.getMessage());
        body.put("path", request.getDescription(false).replace("uri=", ""));

        return new ResponseEntity<>(body, HttpStatus.BAD_REQUEST);
    }

    @ExceptionHandler(RuntimeException.class)
    public ResponseEntity<Object> handleRuntimeException(RuntimeException ex, WebRequest request) {
        log.error("Runtime error occurred", ex);
        
        Map<String, Object> body = new LinkedHashMap<>();
        body.put("timestamp", LocalDateTime.now());
        body.put("status", HttpStatus.INTERNAL_SERVER_ERROR.value());
        body.put("error", "Internal Server Error");
        body.put("message", ex.getMessage());
        body.put("path", request.getDescription(false).replace("uri=", ""));

        return new ResponseEntity<>(body, HttpStatus.INTERNAL_SERVER_ERROR);
    }
}

// FILE: src\main\java\com\flowforge\trigger\kafka\producer\TriggerEventProducer.java
========================================
package com.flowforge.trigger.kafka.producer;

import com.flowforge.trigger.dto.TriggerEvent;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.SendResult;
import org.springframework.stereotype.Component;

import java.util.concurrent.CompletableFuture;

@Component
@RequiredArgsConstructor
@Slf4j
public class TriggerEventProducer {

    private final KafkaTemplate<String, Object> kafkaTemplate;

    @Value("${kafka.topic.trigger-events}")
    private String triggerEventsTopic;

    public void sendTriggerEvent(TriggerEvent event) {
        log.info("Sending trigger event: {} to topic: {}", event.getEventId(), triggerEventsTopic);
        
        CompletableFuture<SendResult<String, Object>> future = 
            kafkaTemplate.send(triggerEventsTopic, event.getEventId(), event);
        
        future.whenComplete((result, ex) -> {
            if (ex == null) {
                log.info("Successfully sent trigger event: {} with offset: {}", 
                    event.getEventId(), 
                    result.getRecordMetadata().offset());
            } else {
                log.error("Failed to send trigger event: {}", event.getEventId(), ex);
            }
        });
    }

    public void sendTriggerEventSync(TriggerEvent event) {
        try {
            log.info("Sending trigger event synchronously: {} to topic: {}", 
                event.getEventId(), triggerEventsTopic);
            
            SendResult<String, Object> result = 
                kafkaTemplate.send(triggerEventsTopic, event.getEventId(), event).get();
            
            log.info("Successfully sent trigger event: {} with offset: {}", 
                event.getEventId(), 
                result.getRecordMetadata().offset());
        } catch (Exception e) {
            log.error("Failed to send trigger event: {}", event.getEventId(), e);
            throw new RuntimeException("Failed to send trigger event", e);
        }
    }
}

// FILE: src\main\java\com\flowforge\trigger\plugin\BaseTriggerPlugin.java
========================================
package com.flowforge.trigger.plugin;

import com.flowforge.trigger.dto.TriggerEvent;
import lombok.extern.slf4j.Slf4j;

import java.time.Instant;
import java.util.HashMap;
import java.util.Map;
import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;

/**
 * Abstract base class for trigger plugins.
 * Provides common functionality and default implementations.
 */
@Slf4j
public abstract class BaseTriggerPlugin implements TriggerPlugin {
    
    protected final Map<String, Map<String, Object>> activeWorkflows = new ConcurrentHashMap<>();
    protected boolean initialized = false;
    protected boolean healthy = true;
    
    @Override
    public void initialize(Map<String, Object> config) throws Exception {
        log.info("Initializing trigger plugin: {}", getType());
        this.initialized = true;
    }
    
    @Override
    public void start(String workflowId, Map<String, Object> config) throws Exception {
        if (!initialized) {
            throw new IllegalStateException("Plugin not initialized");
        }
        
        if (!validateConfig(config)) {
            throw new IllegalArgumentException("Invalid configuration for trigger: " + getType());
        }
        
        log.info("Starting trigger {} for workflow: {}", getType(), workflowId);
        activeWorkflows.put(workflowId, config);
    }
    
    @Override
    public void stop(String workflowId) throws Exception {
        log.info("Stopping trigger {} for workflow: {}", getType(), workflowId);
        activeWorkflows.remove(workflowId);
    }
    
    @Override
    public boolean validateConfig(Map<String, Object> config) {
        // Default implementation - can be overridden
        return config != null;
    }
    
    @Override
    public TriggerEvent processEvent(Map<String, Object> payload, Map<String, String> metadata) {
        return TriggerEvent.builder()
                .eventId(UUID.randomUUID().toString())
                .triggerType(getType())
                .payload(payload != null ? payload : new HashMap<>())
                .metadata(metadata != null ? metadata : new HashMap<>())
                .timestamp(Instant.now())
                .createdAt(Instant.now())
                .build();
    }
    
    @Override
    public boolean isHealthy() {
        return initialized && healthy;
    }
    
    @Override
    public Map<String, Object> getStatus() {
        Map<String, Object> status = new HashMap<>();
        status.put("type", getType());
        status.put("name", getName());
        status.put("initialized", initialized);
        status.put("healthy", healthy);
        status.put("activeWorkflows", activeWorkflows.size());
        status.put("workflowIds", activeWorkflows.keySet());
        return status;
    }
    
    @Override
    public void destroy() {
        log.info("Destroying trigger plugin: {}", getType());
        activeWorkflows.clear();
        initialized = false;
    }
    
    protected void setHealthy(boolean healthy) {
        this.healthy = healthy;
    }
    
    protected boolean isWorkflowActive(String workflowId) {
        return activeWorkflows.containsKey(workflowId);
    }
    
    protected Map<String, Object> getWorkflowConfig(String workflowId) {
        return activeWorkflows.get(workflowId);
    }
}

// FILE: src\main\java\com\flowforge\trigger\plugin\impl\EmailTriggerPlugin.java
========================================
package com.flowforge.trigger.plugin.impl;

import com.flowforge.trigger.dto.TriggerEvent;
import com.flowforge.trigger.plugin.BaseTriggerPlugin;
import lombok.extern.slf4j.Slf4j;

import java.time.Instant;
import java.util.HashMap;
import java.util.Map;
import java.util.UUID;

/**
 * Example: Email trigger plugin
 * This would monitor an email inbox and trigger workflows when emails arrive
 * 
 * To use as external plugin:
 * 1. Compile this class into a JAR
 * 2. Add MANIFEST.MF with: Trigger-Plugin-Class: com.flowforge.trigger.plugin.impl.EmailTriggerPlugin
 * 3. Copy JAR to ./plugins/triggers/ directory
 * 4. Plugin will be loaded automatically (or call /api/v1/plugins/reload)
 */
@Slf4j
public class EmailTriggerPlugin extends BaseTriggerPlugin {
    
    private Thread emailMonitorThread;
    private volatile boolean running = false;
    
    @Override
    public String getType() {
        return "email";
    }
    
    @Override
    public String getName() {
        return "Email Trigger";
    }
    
    @Override
    public String getDescription() {
        return "Triggers workflow when an email is received";
    }
    
    @Override
    public Map<String, Object> getConfigSchema() {
        Map<String, Object> schema = new HashMap<>();
        schema.put("type", "object");
        
        Map<String, Object> properties = new HashMap<>();
        
        // Email server config
        Map<String, Object> serverProp = new HashMap<>();
        serverProp.put("type", "string");
        serverProp.put("description", "IMAP server address");
        serverProp.put("example", "imap.gmail.com");
        properties.put("server", serverProp);
        
        Map<String, Object> portProp = new HashMap<>();
        portProp.put("type", "integer");
        portProp.put("default", 993);
        properties.put("port", portProp);
        
        Map<String, Object> usernameProp = new HashMap<>();
        usernameProp.put("type", "string");
        usernameProp.put("description", "Email username");
        properties.put("username", usernameProp);
        
        Map<String, Object> passwordProp = new HashMap<>();
        passwordProp.put("type", "string");
        passwordProp.put("description", "Email password");
        passwordProp.put("format", "password");
        properties.put("password", passwordProp);
        
        Map<String, Object> folderProp = new HashMap<>();
        folderProp.put("type", "string");
        folderProp.put("default", "INBOX");
        properties.put("folder", folderProp);
        
        // Filter options
        Map<String, Object> subjectFilterProp = new HashMap<>();
        subjectFilterProp.put("type", "string");
        subjectFilterProp.put("description", "Filter by subject (regex)");
        properties.put("subjectFilter", subjectFilterProp);
        
        Map<String, Object> fromFilterProp = new HashMap<>();
        fromFilterProp.put("type", "string");
        fromFilterProp.put("description", "Filter by sender email");
        properties.put("fromFilter", fromFilterProp);
        
        schema.put("properties", properties);
        schema.put("required", new String[]{"server", "username", "password"});
        
        return schema;
    }
    
    @Override
    public boolean validateConfig(Map<String, Object> config) {
        if (config == null) {
            return false;
        }
        
        // Validate required fields
        String[] required = {"server", "username", "password"};
        for (String field : required) {
            if (!config.containsKey(field) || config.get(field) == null) {
                log.error("Email trigger missing required field: {}", field);
                return false;
            }
        }
        
        return true;
    }
    
    @Override
    public void initialize(Map<String, Object> config) throws Exception {
        super.initialize(config);
        log.info("Email trigger plugin initialized");
    }
    
    @Override
    public void start(String workflowId, Map<String, Object> config) throws Exception {
        super.start(workflowId, config);
        
        // Start email monitoring if not already running
        if (!running) {
            startEmailMonitoring();
        }
        
        log.info("Email trigger started for workflow: {}", workflowId);
    }
    
    @Override
    public void stop(String workflowId) throws Exception {
        super.stop(workflowId);
        
        // Stop monitoring if no workflows are active
        if (activeWorkflows.isEmpty() && running) {
            stopEmailMonitoring();
        }
        
        log.info("Email trigger stopped for workflow: {}", workflowId);
    }
    
    private void startEmailMonitoring() {
        running = true;
        emailMonitorThread = new Thread(() -> {
            log.info("Email monitoring thread started");
            
            while (running) {
                try {
                    // Simulate email checking
                    // In real implementation, connect to IMAP server and check for new emails
                    
                    checkEmails();
                    
                    // Check every 30 seconds
                    Thread.sleep(30000);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    break;
                } catch (Exception e) {
                    log.error("Error monitoring emails", e);
                    setHealthy(false);
                }
            }
            
            log.info("Email monitoring thread stopped");
        });
        emailMonitorThread.setName("email-monitor");
        emailMonitorThread.setDaemon(true);
        emailMonitorThread.start();
    }
    
    private void stopEmailMonitoring() {
        running = false;
        if (emailMonitorThread != null) {
            emailMonitorThread.interrupt();
            try {
                emailMonitorThread.join(5000);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
    }
    
    private void checkEmails() {
        // Simulate checking emails for all active workflows
        // In real implementation:
        // 1. Connect to IMAP server
        // 2. Check for new/unread emails
        // 3. Apply filters based on workflow config
        // 4. Create trigger events for matching emails
        
        log.debug("Checking emails for {} workflows", activeWorkflows.size());
        
        // Example: simulate finding an email
        if (Math.random() < 0.1) { // 10% chance for demo
            activeWorkflows.forEach((workflowId, config) -> {
                TriggerEvent event = TriggerEvent.builder()
                    .eventId(UUID.randomUUID().toString())
                    .triggerType(getType())
                    .payload(Map.of(
                        "from", "sender@example.com",
                        "subject", "Test Email",
                        "body", "This is a test email body",
                        "receivedAt", Instant.now().toString()
                    ))
                    .metadata(Map.of(
                        "workflowId", workflowId,
                        "triggerSource", "email"
                    ))
                    .timestamp(Instant.now())
                    .build();
                
                // In real implementation, you'd call triggerService.processTrigger(event)
                log.info("Would trigger workflow {} for email", workflowId);
            });
        }
    }
    
    @Override
    public void destroy() {
        stopEmailMonitoring();
        super.destroy();
        log.info("Email trigger plugin destroyed");
    }
    
    @Override
    public Map<String, Object> getStatus() {
        Map<String, Object> status = super.getStatus();
        status.put("monitoring", running);
        status.put("monitorThread", emailMonitorThread != null ? 
            emailMonitorThread.getState().toString() : "NOT_STARTED");
        return status;
    }
}

// FILE: src\main\java\com\flowforge\trigger\plugin\impl\ScheduleTriggerPlugin.java
========================================
package com.flowforge.trigger.plugin.impl;

import com.flowforge.trigger.dto.TriggerEvent;
import com.flowforge.trigger.plugin.BaseTriggerPlugin;
import com.flowforge.trigger.service.TriggerService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.TaskScheduler;
import org.springframework.scheduling.support.CronTrigger;
import org.springframework.stereotype.Component;

import java.time.Instant;
import java.util.HashMap;
import java.util.Map;
import java.util.UUID;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ScheduledFuture;

/**
 * Built-in schedule trigger plugin.
 * Handles cron-based scheduled triggers.
 */
@Component
@Slf4j
@RequiredArgsConstructor
public class ScheduleTriggerPlugin extends BaseTriggerPlugin {
    
    private final TaskScheduler taskScheduler;
    private final TriggerService triggerService;
    private final Map<String, ScheduledFuture<?>> scheduledTasks = new ConcurrentHashMap<>();
    
    @Override
    public String getType() {
        return "schedule";
    }
    
    @Override
    public String getName() {
        return "Schedule Trigger";
    }
    
    @Override
    public String getDescription() {
        return "Triggers workflow based on a cron schedule";
    }
    
    @Override
    public Map<String, Object> getConfigSchema() {
        Map<String, Object> schema = new HashMap<>();
        schema.put("type", "object");
        
        Map<String, Object> properties = new HashMap<>();
        
        // Cron expression
        Map<String, Object> cronProp = new HashMap<>();
        cronProp.put("type", "string");
        cronProp.put("description", "Cron expression (e.g., '0 0 * * * ?' for hourly)");
        cronProp.put("example", "0 */5 * * * ?");
        properties.put("cronExpression", cronProp);
        
        // Timezone
        Map<String, Object> timezoneProp = new HashMap<>();
        timezoneProp.put("type", "string");
        timezoneProp.put("description", "Timezone for schedule");
        timezoneProp.put("default", "UTC");
        properties.put("timezone", timezoneProp);
        
        schema.put("properties", properties);
        schema.put("required", new String[]{"cronExpression"});
        
        return schema;
    }
    
    @Override
    public boolean validateConfig(Map<String, Object> config) {
        if (config == null) {
            return false;
        }
        
        if (!config.containsKey("cronExpression")) {
            log.error("Schedule trigger requires 'cronExpression'");
            return false;
        }
        
        try {
            String cronExpression = (String) config.get("cronExpression");
            new CronTrigger(cronExpression);
            return true;
        } catch (Exception e) {
            log.error("Invalid cron expression", e);
            return false;
        }
    }
    
    @Override
    public void start(String workflowId, Map<String, Object> config) throws Exception {
        super.start(workflowId, config);
        
        String cronExpression = (String) config.get("cronExpression");
        
        // Schedule the task
        ScheduledFuture<?> scheduledTask = taskScheduler.schedule(
            () -> executeScheduledTrigger(workflowId, config),
            new CronTrigger(cronExpression)
        );
        
        scheduledTasks.put(workflowId, scheduledTask);
        
        log.info("Schedule trigger started for workflow: {} with cron: {}", 
            workflowId, cronExpression);
    }
    
    @Override
    public void stop(String workflowId) throws Exception {
        ScheduledFuture<?> scheduledTask = scheduledTasks.remove(workflowId);
        if (scheduledTask != null) {
            scheduledTask.cancel(false);
            log.info("Schedule trigger stopped for workflow: {}", workflowId);
        }
        super.stop(workflowId);
    }
    
    private void executeScheduledTrigger(String workflowId, Map<String, Object> config) {
        try {
            log.debug("Executing scheduled trigger for workflow: {}", workflowId);
            
            TriggerEvent event = TriggerEvent.builder()
                .eventId(UUID.randomUUID().toString())
                .triggerType(getType())
                .payload(Map.of(
                    "workflowId", workflowId,
                    "cronExpression", config.get("cronExpression"),
                    "executionTime", Instant.now().toString()
                ))
                .metadata(Map.of(
                    "workflowId", workflowId,
                    "triggerSource", "schedule"
                ))
                .timestamp(Instant.now())
                .build();
            
            triggerService.processTrigger(event);
        } catch (Exception e) {
            log.error("Error executing scheduled trigger for workflow: {}", workflowId, e);
        }
    }
    
    @Override
    public Map<String, Object> getStatus() {
        Map<String, Object> status = super.getStatus();
        status.put("activeSchedules", scheduledTasks.size());
        status.put("schedules", activeWorkflows.entrySet().stream()
            .map(entry -> Map.of(
                "workflowId", entry.getKey(),
                "cronExpression", entry.getValue().get("cronExpression"),
                "active", scheduledTasks.containsKey(entry.getKey())
            ))
            .toList());
        return status;
    }
    
    @Override
    public void destroy() {
        scheduledTasks.values().forEach(task -> task.cancel(false));
        scheduledTasks.clear();
        super.destroy();
    }
}

// FILE: src\main\java\com\flowforge\trigger\plugin\impl\WebhookTriggerPlugin.java
========================================
package com.flowforge.trigger.plugin.impl;

import com.flowforge.trigger.plugin.BaseTriggerPlugin;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

import java.util.HashMap;
import java.util.Map;

/**
 * Built-in webhook trigger plugin.
 * Handles HTTP webhook events.
 */
@Component
@Slf4j
public class WebhookTriggerPlugin extends BaseTriggerPlugin {
    
    @Override
    public String getType() {
        return "webhook";
    }
    
    @Override
    public String getName() {
        return "Webhook Trigger";
    }
    
    @Override
    public String getDescription() {
        return "Triggers workflow when an HTTP webhook is received";
    }
    
    @Override
    public Map<String, Object> getConfigSchema() {
        Map<String, Object> schema = new HashMap<>();
        schema.put("type", "object");
        
        Map<String, Object> properties = new HashMap<>();
        
        // Path property
        Map<String, Object> pathProp = new HashMap<>();
        pathProp.put("type", "string");
        pathProp.put("description", "Webhook endpoint path");
        pathProp.put("example", "/webhooks/my-workflow");
        properties.put("path", pathProp);
        
        // Method property
        Map<String, Object> methodProp = new HashMap<>();
        methodProp.put("type", "string");
        methodProp.put("enum", new String[]{"POST", "GET", "PUT", "DELETE", "PATCH"});
        methodProp.put("default", "POST");
        properties.put("method", methodProp);
        
        // Authentication property
        Map<String, Object> authProp = new HashMap<>();
        authProp.put("type", "object");
        Map<String, Object> authProps = new HashMap<>();
        
        Map<String, Object> authType = new HashMap<>();
        authType.put("type", "string");
        authType.put("enum", new String[]{"none", "basic", "bearer", "api_key"});
        authProps.put("type", authType);
        
        Map<String, Object> authValue = new HashMap<>();
        authValue.put("type", "string");
        authValue.put("description", "Authentication token/key");
        authProps.put("value", authValue);
        
        authProp.put("properties", authProps);
        properties.put("authentication", authProp);
        
        schema.put("properties", properties);
        schema.put("required", new String[]{"path"});
        
        return schema;
    }
    
    @Override
    public boolean validateConfig(Map<String, Object> config) {
        if (config == null) {
            return false;
        }
        
        // Path is required
        if (!config.containsKey("path") || config.get("path") == null) {
            log.error("Webhook trigger requires 'path' configuration");
            return false;
        }
        
        return true;
    }
    
    @Override
    public void start(String workflowId, Map<String, Object> config) throws Exception {
        super.start(workflowId, config);
        log.info("Webhook trigger started for workflow: {} at path: {}", 
            workflowId, config.get("path"));
    }
    
    @Override
    public void stop(String workflowId) throws Exception {
        super.stop(workflowId);
        log.info("Webhook trigger stopped for workflow: {}", workflowId);
    }
    
    @Override
    public Map<String, Object> getStatus() {
        Map<String, Object> status = super.getStatus();
        status.put("endpoints", activeWorkflows.entrySet().stream()
            .map(entry -> Map.of(
                "workflowId", entry.getKey(),
                "path", entry.getValue().get("path"),
                "method", entry.getValue().getOrDefault("method", "POST")
            ))
            .toList());
        return status;
    }
}

// FILE: src\main\java\com\flowforge\trigger\plugin\TriggerPlugin.java
========================================
package com.flowforge.trigger.plugin;

import com.flowforge.trigger.dto.TriggerEvent;

import java.util.Map;

/**
 * Base interface for all trigger plugins.
 * Implement this interface to create custom trigger types.
 */
public interface TriggerPlugin {
    
    /**
     * Unique identifier for this trigger plugin
     * Examples: "webhook", "schedule", "email", "slack", "github"
     */
    String getType();
    
    /**
     * Human-readable name for this trigger
     */
    String getName();
    
    /**
     * Description of what this trigger does
     */
    String getDescription();
    
    /**
     * Configuration schema for this trigger (JSON Schema format)
     * Defines what configuration fields are required
     */
    Map<String, Object> getConfigSchema();
    
    /**
     * Initialize the trigger with configuration
     * Called when the trigger is first loaded or when configuration changes
     * 
     * @param config Configuration map from workflow definition
     * @throws Exception if initialization fails
     */
    void initialize(Map<String, Object> config) throws Exception;
    
    /**
     * Start listening for trigger events
     * Called when a workflow with this trigger is enabled
     * 
     * @param workflowId The workflow ID this trigger is associated with
     * @param config The trigger configuration
     * @throws Exception if start fails
     */
    void start(String workflowId, Map<String, Object> config) throws Exception;
    
    /**
     * Stop listening for trigger events
     * Called when a workflow is disabled or deleted
     * 
     * @param workflowId The workflow ID to stop
     * @throws Exception if stop fails
     */
    void stop(String workflowId) throws Exception;
    
    /**
     * Validate the trigger configuration
     * 
     * @param config The configuration to validate
     * @return true if valid, false otherwise
     */
    boolean validateConfig(Map<String, Object> config);
    
    /**
     * Process an incoming trigger event
     * This method is called when an event occurs that should trigger workflows
     * 
     * @param payload The event payload
     * @param metadata Additional metadata about the event
     * @return TriggerEvent to be published to Kafka
     */
    TriggerEvent processEvent(Map<String, Object> payload, Map<String, String> metadata);
    
    /**
     * Check if the trigger is currently active and healthy
     */
    boolean isHealthy();
    
    /**
     * Get current status information about the trigger
     */
    Map<String, Object> getStatus();
    
    /**
     * Cleanup resources when the trigger is being unloaded
     */
    void destroy();
}

// FILE: src\main\java\com\flowforge\trigger\plugin\TriggerPluginManager.java
========================================
package com.flowforge.trigger.plugin;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;

import jakarta.annotation.PostConstruct;
import jakarta.annotation.PreDestroy;
import java.io.File;
import java.net.URL;
import java.net.URLClassLoader;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.jar.JarFile;

/**
 * Manages trigger plugins - loading, registering, and lifecycle management.
 * Supports hot-reload of plugins without server restart.
 */
@Component
@Slf4j
public class TriggerPluginManager {
    
    private final Map<String, TriggerPlugin> plugins = new ConcurrentHashMap<>();
    private final Map<String, ClassLoader> pluginClassLoaders = new ConcurrentHashMap<>();
    private final String pluginsDirectory = System.getProperty("plugins.dir", "./plugins/triggers");
    
    @PostConstruct
    public void initialize() {
        log.info("Initializing TriggerPluginManager");
        log.info("Plugins directory: {}", pluginsDirectory);
        
        // Create plugins directory if it doesn't exist
        File pluginsDir = new File(pluginsDirectory);
        if (!pluginsDir.exists()) {
            pluginsDir.mkdirs();
            log.info("Created plugins directory: {}", pluginsDirectory);
        }
        
        // Scan and load built-in plugins first
        loadBuiltInPlugins();
        
        // Load external plugins
        scanAndLoadPlugins();
        
        log.info("Loaded {} trigger plugins", plugins.size());
    }
    
    /**
     * Load built-in plugins that are part of the application
     */
    private void loadBuiltInPlugins() {
        log.info("Loading built-in plugins...");
        // Built-in plugins will be auto-discovered via Spring component scan
    }
    
    /**
     * Register a plugin (called by Spring for @Component plugins or manually)
     */
    public void registerPlugin(TriggerPlugin plugin) {
        try {
            String type = plugin.getType();
            
            if (plugins.containsKey(type)) {
                log.warn("Plugin {} already registered, replacing...", type);
                unregisterPlugin(type);
            }
            
            plugin.initialize(new HashMap<>());
            plugins.put(type, plugin);
            
            log.info("Registered trigger plugin: {} ({})", plugin.getName(), type);
        } catch (Exception e) {
            log.error("Failed to register plugin: {}", plugin.getType(), e);
        }
    }
    
    /**
     * Unregister a plugin
     */
    public void unregisterPlugin(String type) {
        TriggerPlugin plugin = plugins.get(type);
        if (plugin != null) {
            try {
                plugin.destroy();
                plugins.remove(type);
                
                // Cleanup class loader
                ClassLoader classLoader = pluginClassLoaders.remove(type);
                if (classLoader instanceof URLClassLoader) {
                    ((URLClassLoader) classLoader).close();
                }
                
                log.info("Unregistered trigger plugin: {}", type);
            } catch (Exception e) {
                log.error("Error unregistering plugin: {}", type, e);
            }
        }
    }
    
    /**
     * Get a plugin by type
     */
    public Optional<TriggerPlugin> getPlugin(String type) {
        return Optional.ofNullable(plugins.get(type));
    }
    
    /**
     * Get all registered plugins
     */
    public Map<String, TriggerPlugin> getAllPlugins() {
        return new HashMap<>(plugins);
    }
    
    /**
     * Scan and load plugins from the plugins directory
     */
    public void scanAndLoadPlugins() {
        File pluginsDir = new File(pluginsDirectory);
        if (!pluginsDir.exists() || !pluginsDir.isDirectory()) {
            log.warn("Plugins directory does not exist: {}", pluginsDirectory);
            return;
        }
        
        File[] jarFiles = pluginsDir.listFiles((dir, name) -> name.endsWith(".jar"));
        if (jarFiles == null || jarFiles.length == 0) {
            log.info("No plugin JAR files found in: {}", pluginsDirectory);
            return;
        }
        
        log.info("Found {} plugin JAR files", jarFiles.length);
        
        for (File jarFile : jarFiles) {
            try {
                loadPluginFromJar(jarFile);
            } catch (Exception e) {
                log.error("Failed to load plugin from: {}", jarFile.getName(), e);
            }
        }
    }
    
    /**
     * Load a plugin from a JAR file
     */
    private void loadPluginFromJar(File jarFile) throws Exception {
        log.info("Loading plugin from: {}", jarFile.getName());
        
        // Create class loader for the plugin
        URL[] urls = {jarFile.toURI().toURL()};
        URLClassLoader classLoader = new URLClassLoader(urls, getClass().getClassLoader());
        
        // Read plugin metadata from JAR
        try (JarFile jar = new JarFile(jarFile)) {
            var manifest = jar.getManifest();
            if (manifest == null) {
                log.warn("No manifest found in: {}", jarFile.getName());
                return;
            }
            
            String pluginClass = manifest.getMainAttributes().getValue("Trigger-Plugin-Class");
            if (pluginClass == null) {
                log.warn("No Trigger-Plugin-Class attribute in manifest: {}", jarFile.getName());
                return;
            }
            
            // Load and instantiate the plugin
            Class<?> clazz = classLoader.loadClass(pluginClass);
            if (!TriggerPlugin.class.isAssignableFrom(clazz)) {
                log.error("Class {} does not implement TriggerPlugin", pluginClass);
                return;
            }
            
            TriggerPlugin plugin = (TriggerPlugin) clazz.getDeclaredConstructor().newInstance();
            
            // Store class loader
            pluginClassLoaders.put(plugin.getType(), classLoader);
            
            // Register the plugin
            registerPlugin(plugin);
            
            log.info("Successfully loaded plugin: {} from {}", plugin.getName(), jarFile.getName());
        }
    }
    
    /**
     * Reload a specific plugin
     */
    public void reloadPlugin(String type) {
        log.info("Reloading plugin: {}", type);
        unregisterPlugin(type);
        scanAndLoadPlugins();
    }
    
    /**
     * Reload all plugins
     */
    public void reloadAllPlugins() {
        log.info("Reloading all plugins...");
        
        // Unregister all external plugins (keep built-in ones)
        List<String> externalPlugins = new ArrayList<>();
        plugins.forEach((type, plugin) -> {
            if (pluginClassLoaders.containsKey(type)) {
                externalPlugins.add(type);
            }
        });
        
        externalPlugins.forEach(this::unregisterPlugin);
        
        // Rescan and load
        scanAndLoadPlugins();
        
        log.info("Reloaded all plugins. Total plugins: {}", plugins.size());
    }
    
    /**
     * Start a trigger for a workflow
     */
    public void startTrigger(String type, String workflowId, Map<String, Object> config) throws Exception {
        TriggerPlugin plugin = plugins.get(type);
        if (plugin == null) {
            throw new IllegalArgumentException("Plugin not found: " + type);
        }
        plugin.start(workflowId, config);
    }
    
    /**
     * Stop a trigger for a workflow
     */
    public void stopTrigger(String type, String workflowId) throws Exception {
        TriggerPlugin plugin = plugins.get(type);
        if (plugin == null) {
            throw new IllegalArgumentException("Plugin not found: " + type);
        }
        plugin.stop(workflowId);
    }
    
    /**
     * Get status of all plugins
     */
    public Map<String, Object> getPluginsStatus() {
        Map<String, Object> status = new HashMap<>();
        status.put("totalPlugins", plugins.size());
        status.put("pluginsDirectory", pluginsDirectory);
        
        Map<String, Map<String, Object>> pluginStatuses = new HashMap<>();
        plugins.forEach((type, plugin) -> pluginStatuses.put(type, plugin.getStatus()));
        status.put("plugins", pluginStatuses);
        
        return status;
    }
    
    @PreDestroy
    public void cleanup() {
        log.info("Cleaning up TriggerPluginManager...");
        plugins.values().forEach(TriggerPlugin::destroy);
        
        // Close all class loaders
        pluginClassLoaders.values().forEach(classLoader -> {
            if (classLoader instanceof URLClassLoader) {
                try {
                    ((URLClassLoader) classLoader).close();
                } catch (Exception e) {
                    log.error("Error closing class loader", e);
                }
            }
        });
        
        plugins.clear();
        pluginClassLoaders.clear();
    }
}

// FILE: src\main\java\com\flowforge\trigger\service\SchedulerService.java
========================================
package com.flowforge.trigger.service;

import com.flowforge.trigger.dto.TriggerEvent;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;

import java.time.Instant;
import java.util.HashMap;
import java.util.Map;
import java.util.UUID;

/**
 * Service for handling scheduled triggers
 * This is a simple implementation - in production you might want to:
 * - Store schedule configs in database
 * - Use dynamic scheduling (Quartz, etc.)
 * - Allow users to configure cron expressions
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class SchedulerService {

    private final TriggerService triggerService;

    /**
     * Example: Run every minute
     * Cron format: second, minute, hour, day, month, weekday
     */
    @Scheduled(cron = "0 * * * * ?")
    public void everyMinuteSchedule() {
        log.debug("Running every minute schedule");
        
        TriggerEvent event = TriggerEvent.builder()
                .eventId(UUID.randomUUID().toString())
                .triggerType("schedule.every_minute")
                .payload(Map.of(
                    "scheduleName", "every_minute",
                    "executionTime", Instant.now().toString()
                ))
                .metadata(Map.of("source", "scheduler"))
                .timestamp(Instant.now())
                .build();
        
        triggerService.processTrigger(event);
    }

    /**
     * Example: Run every 5 minutes
     */
    @Scheduled(cron = "0 */5 * * * ?")
    public void everyFiveMinutesSchedule() {
        log.debug("Running every 5 minutes schedule");
        
        TriggerEvent event = TriggerEvent.builder()
                .eventId(UUID.randomUUID().toString())
                .triggerType("schedule.every_5_minutes")
                .payload(Map.of(
                    "scheduleName", "every_5_minutes",
                    "executionTime", Instant.now().toString()
                ))
                .metadata(Map.of("source", "scheduler"))
                .timestamp(Instant.now())
                .build();
        
        triggerService.processTrigger(event);
    }

    /**
     * Example: Run every hour
     */
    @Scheduled(cron = "0 0 * * * ?")
    public void everyHourSchedule() {
        log.info("Running every hour schedule");
        
        TriggerEvent event = TriggerEvent.builder()
                .eventId(UUID.randomUUID().toString())
                .triggerType("schedule.hourly")
                .payload(Map.of(
                    "scheduleName", "hourly",
                    "executionTime", Instant.now().toString()
                ))
                .metadata(Map.of("source", "scheduler"))
                .timestamp(Instant.now())
                .build();
        
        triggerService.processTrigger(event);
    }

    /**
     * Example: Run daily at midnight
     */
    @Scheduled(cron = "0 0 0 * * ?")
    public void dailySchedule() {
        log.info("Running daily schedule");
        
        TriggerEvent event = TriggerEvent.builder()
                .eventId(UUID.randomUUID().toString())
                .triggerType("schedule.daily")
                .payload(Map.of(
                    "scheduleName", "daily",
                    "executionTime", Instant.now().toString()
                ))
                .metadata(Map.of("source", "scheduler"))
                .timestamp(Instant.now())
                .build();
        
        triggerService.processTrigger(event);
    }

    /**
     * Trigger a custom schedule manually
     */
    public String triggerCustomSchedule(String scheduleName, Map<String, Object> config) {
        log.info("Manually triggering custom schedule: {}", scheduleName);
        
        String eventId = UUID.randomUUID().toString();
        Map<String, Object> payload = new HashMap<>(config);
        payload.put("scheduleName", scheduleName);
        payload.put("executionTime", Instant.now().toString());
        payload.put("manual", true);
        
        TriggerEvent event = TriggerEvent.builder()
                .eventId(eventId)
                .triggerType("schedule." + scheduleName)
                .payload(payload)
                .metadata(Map.of(
                    "source", "scheduler",
                    "manual", "true"
                ))
                .timestamp(Instant.now())
                .build();
        
        triggerService.processTrigger(event);
        return eventId;
    }
}

// FILE: src\main\java\com\flowforge\trigger\service\TriggerService.java
========================================
package com.flowforge.trigger.service;

import com.flowforge.trigger.dto.TriggerEvent;
import com.flowforge.trigger.kafka.producer.TriggerEventProducer;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.time.Instant;
import java.util.Map;
import java.util.UUID;

@Service
@RequiredArgsConstructor
@Slf4j
public class TriggerService {

    private final TriggerEventProducer triggerEventProducer;

    /**
     * Process a trigger event by sending it to Kafka
     */
    public void processTrigger(TriggerEvent event) {
        log.info("Processing trigger event: {} of type: {}", event.getEventId(), event.getTriggerType());
        
        // Validate the event
        if (event.getEventId() == null || event.getEventId().isEmpty()) {
            event.setEventId(UUID.randomUUID().toString());
        }
        
        if (event.getTimestamp() == null) {
            event.setTimestamp(Instant.now());
        }
        
        // Send to Kafka
        triggerEventProducer.sendTriggerEvent(event);
        
        log.info("Trigger event {} sent to Kafka successfully", event.getEventId());
    }

    /**
     * Process a trigger event synchronously (waits for Kafka confirmation)
     */
    public void processTriggerSync(TriggerEvent event) {
        log.info("Processing trigger event synchronously: {} of type: {}", 
            event.getEventId(), event.getTriggerType());
        
        // Validate the event
        if (event.getEventId() == null || event.getEventId().isEmpty()) {
            event.setEventId(UUID.randomUUID().toString());
        }
        
        if (event.getTimestamp() == null) {
            event.setTimestamp(Instant.now());
        }
        
        // Send to Kafka synchronously
        triggerEventProducer.sendTriggerEventSync(event);
        
        log.info("Trigger event {} sent to Kafka successfully (sync)", event.getEventId());
    }

    /**
     * Create and process a manual trigger
     */
    public String createManualTrigger(String workflowId, Map<String, Object> payload) {
        log.info("Creating manual trigger for workflow: {}", workflowId);
        
        String eventId = UUID.randomUUID().toString();
        TriggerEvent event = TriggerEvent.builder()
                .eventId(eventId)
                .triggerType("manual")
                .payload(payload)
                .metadata(Map.of("workflowId", workflowId))
                .timestamp(Instant.now())
                .build();
        
        processTrigger(event);
        return eventId;
    }

    /**
     * Create and process a scheduled trigger
     */
    public String createScheduledTrigger(String workflowId, String scheduleName, Map<String, Object> config) {
        log.info("Creating scheduled trigger for workflow: {} with schedule: {}", workflowId, scheduleName);
        
        String eventId = UUID.randomUUID().toString();
        TriggerEvent event = TriggerEvent.builder()
                .eventId(eventId)
                .triggerType("schedule." + scheduleName)
                .payload(config)
                .metadata(Map.of(
                    "workflowId", workflowId,
                    "scheduleName", scheduleName
                ))
                .timestamp(Instant.now())
                .build();
        
        processTrigger(event);
        return eventId;
    }
}

// FILE: src\main\java\com\flowforge\trigger\TriggerApplication.java
========================================
package com.flowforge.trigger;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class TriggerApplication {

	static void main(String[] args) {
		SpringApplication.run(TriggerApplication.class, args);
	}

}


// FILE: src\main\resources\application.yml
========================================
server:
  port: 8083

spring:
  application:
    name: trigger-service

  # Kafka Configuration
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: all
      retries: 3
      properties:
        enable.idempotence: true
        max.in.flight.requests.per.connection: 5

# Kafka Topics Configuration
kafka:
  topic:
    trigger-events: trigger.events

# Plugin Configuration
plugins:
  dir: ${PLUGINS_DIR:./plugins/triggers}
  auto-reload: ${PLUGINS_AUTO_RELOAD:false}
  scan-interval: ${PLUGINS_SCAN_INTERVAL:60} # seconds

# Logging Configuration
logging:
  level:
    com.flowforge.trigger: DEBUG
    org.springframework.kafka: INFO
    org.apache.kafka: WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

# Management endpoints for monitoring
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,plugins
  endpoint:
    health:
      show-details: always

